package com.github.bosgalo.crawler;

import java.net.MalformedURLException;
import java.net.URL;
import java.sql.*;
import java.util.HashSet;
import java.util.Set;

public class CrawlerRepository {
    private Connection connection = null;

    private final String DB_URL = "jdbc:mysql://localhost/vuln_scanner?useUnicode=true&useJDBCCompliantTimezoneShift=true&useLegacyDatetimeCode=false&serverTimezone=UTC";
    private final String DB_USER = "root";
    private final String DB_PASSWORD = "tykTYKtyk333";

    public CrawlerRepository() {
        try {
            connection = getConnection();
            init();
        } catch (SQLException e) {
            e.printStackTrace();
        }
    }

    private Connection getConnection() throws SQLException {
        return DriverManager.getConnection(DB_URL, DB_USER, DB_PASSWORD);
    }

    private void init() {
        String tableName = "crawler";
        String createTableIfNotExits = "CREATE TABLE IF NOT EXISTS " + tableName + " (id INT NOT NULL PRIMARY KEY AUTO_INCREMENT, " +
                "URL VARCHAR(255))";
        String truncate = "TRUNCATE TABLE " + tableName;
        try {
            connection.prepareStatement(createTableIfNotExits).execute();
            connection.prepareStatement(truncate).execute();
        } catch (SQLException e) {
            e.printStackTrace();
        }
    }

    public void collectUrls(String url) {
        Set<String> collectUrls = new Crawler(getUrlFromString(url)).collectUrls();
        String[] urls = collectUrls.toArray(new String[collectUrls.size()]);
        String sql = "INSERT INTO crawler(url) VALUES (?)";
        try {
            for (int i = 0; i < urls.length; i++) {
                PreparedStatement preparedStatement = connection.prepareStatement(sql);
                preparedStatement.setString(1, urls[i]);
                preparedStatement.execute();
            }
        } catch (SQLException e) {
            e.printStackTrace();
        }
    }

    public Set<String> getUrls() {
        String sql = "SELECT * FROM crawler";
        Set<String> urls = new HashSet<>();
        try {
            ResultSet resultSet = connection.prepareStatement(sql).executeQuery();
            while (resultSet.next()) {
                urls.add(resultSet.getString("URL"));
            }
            return urls;
        } catch (SQLException e) {
            throw new IllegalStateException(e);
        }
    }

    private URL getUrlFromString(String url) {
        try {
            return new URL(url);
        } catch (MalformedURLException e) {
            throw new IllegalArgumentException(e);
        }
    }
}
