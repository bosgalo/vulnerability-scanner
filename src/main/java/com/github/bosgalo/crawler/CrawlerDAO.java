package com.github.bosgalo.crawler;

import com.github.bosgalo.JdbcConnection;

import java.net.MalformedURLException;
import java.net.URL;
import java.sql.Connection;
import java.sql.PreparedStatement;
import java.sql.ResultSet;
import java.sql.SQLException;
import java.util.HashSet;
import java.util.Set;

public class CrawlerDAO {

    private Connection connection = null;

    public CrawlerDAO() {
        try {
            connection = new JdbcConnection().getConnection();
        } catch (SQLException e) {
            throw new IllegalStateException(e);
        }
    }

    public void collectUrls(String url) {
        Set<String> collectUrls = new Crawler(getUrlFromString(url)).collectUrls();
        String[] urls = collectUrls.toArray(new String[collectUrls.size()]);
        String sql = "INSERT INTO crawler(url) VALUES (?)";
        try {
            for (String s : urls) {
                PreparedStatement preparedStatement = connection.prepareStatement(sql);
                preparedStatement.setString(1, s);
                preparedStatement.execute();
            }
        } catch (SQLException e) {
            throw new IllegalStateException(e);
        }
    }

    public Set<String> getUrls() {
        String sql = "SELECT * FROM crawler";
        Set<String> urls = new HashSet<>();
        try {
            ResultSet resultSet = connection.prepareStatement(sql).executeQuery();
            while (resultSet.next()) {
                urls.add(resultSet.getString("URL"));
            }
            return urls;
        } catch (SQLException e) {
            throw new IllegalStateException(e);
        }
    }

    private URL getUrlFromString(String url) {
        try {
            return new URL(url);
        } catch (MalformedURLException e) {
            throw new IllegalArgumentException(e);
        }
    }
}
